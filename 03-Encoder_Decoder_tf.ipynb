{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I7_hXFkimvae"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ۱. آماده‌سازی داده‌ها (Corpus)\n",
        "en_sentences = [\"hello\", \"bye\"]\n",
        "fa_sentences = [\"<START> سلام <END>\", \"<START> خداحافظ <END>\"]\n",
        "\n",
        "en_vocab = {\"<PAD>\": 0, \"hello\": 1, \"bye\": 2}\n",
        "fa_vocab = {\"<PAD>\": 0, \"<START>\": 1, \"سلام\": 2, \"خداحافظ\": 3, \"<END>\": 4}\n",
        "inv_fa_vocab = {v: k for k, v in fa_vocab.items()}\n",
        "\n",
        "maxlen = 4 # طول ثابت برای سادگی\n",
        "def tokenize(data, vocab):\n",
        "    tokenized = []\n",
        "    for s in data:\n",
        "        ids = [vocab[w] for w in s.split()]\n",
        "        tokenized.append(ids + [0] * (maxlen - len(ids)))\n",
        "    return np.array(tokenized)\n",
        "\n",
        "x_enc = tokenize(en_sentences, en_vocab)\n",
        "# ورودی دکودر (بدون آخرین کلمه) و خروجی هدف (بدون اولین کلمه)\n",
        "x_dec = tokenize([\" \".join(s.split()[:-1]) for s in fa_sentences], fa_vocab)\n",
        "y_train = tokenize([\" \".join(s.split()[1:]) for s in fa_sentences], fa_vocab)"
      ],
      "metadata": {
        "id": "7PJSt1P8m0t9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ۲. لایه Positional Encoding\n",
        "class PositionalEncoding(layers.Layer):\n",
        "    def __init__(self, maxlen, embed_dim):\n",
        "        super().__init__()\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "    def call(self, x):\n",
        "        positions = tf.range(start=0, limit=tf.shape(x)[1], delta=1)\n",
        "        return x + self.pos_emb(positions)"
      ],
      "metadata": {
        "id": "-Pl2pQUHm3WU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ۳. لایه Encoder\n",
        "class EncoderLayer(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim):\n",
        "        super().__init__()\n",
        "        self.mha = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim)])\n",
        "        self.ln1, self.ln2 = layers.LayerNormalization(), layers.LayerNormalization()\n",
        "\n",
        "    def call(self, x):\n",
        "        attn = self.mha(x, x)\n",
        "        x = self.ln1(x + attn) # Add & Norm\n",
        "        return self.ln2(x + self.ffn(x)) # Add & Norm"
      ],
      "metadata": {
        "id": "Df41gLJbm_Od"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ۴. لایه Decoder (با رفع ارور ماسک)\n",
        "class DecoderLayer(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim):\n",
        "        super().__init__()\n",
        "        self.self_attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.cross_attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tf.keras.Sequential([layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim)])\n",
        "        self.ln1, self.ln2, self.ln3 = layers.LayerNormalization(), layers.LayerNormalization(), layers.LayerNormalization()\n",
        "\n",
        "    def call(self, x, enc_output):\n",
        "        # ساخت ماسک به صورت داینامیک در زمان اجرا\n",
        "        s = tf.shape(x)[1]\n",
        "        mask = 1 - tf.linalg.band_part(tf.ones((s, s)), -1, 0)\n",
        "\n",
        "        # ۱. Masked Self-Attention\n",
        "        x = self.ln1(x + self.self_attn(x, x, attention_mask=mask))\n",
        "        # ۲. Cross-Attention\n",
        "        x = self.ln2(x + self.cross_attn(x, enc_output))\n",
        "        # ۳. Feed Forward\n",
        "        return self.ln3(x + self.ffn(x))"
      ],
      "metadata": {
        "id": "N9aA_hPznFFa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ۵. ساخت مدل نهایی\n",
        "embed_dim, n_heads, ff_dim = 64, 4, 128\n",
        "enc_in = layers.Input(shape=(maxlen,))\n",
        "dec_in = layers.Input(shape=(maxlen,))\n",
        "\n",
        "# مسیر انکودر\n",
        "x = layers.Embedding(len(en_vocab), embed_dim)(enc_in)\n",
        "x = PositionalEncoding(maxlen, embed_dim)(x)\n",
        "enc_out = EncoderLayer(embed_dim, n_heads, ff_dim)(x)\n",
        "\n",
        "# مسیر دکودر\n",
        "x = layers.Embedding(len(fa_vocab), embed_dim)(dec_in)\n",
        "x = PositionalEncoding(maxlen, embed_dim)(x)\n",
        "dec_out = DecoderLayer(embed_dim, n_heads, ff_dim)(x, enc_out)\n",
        "\n",
        "outputs = layers.Dense(len(fa_vocab), activation=\"softmax\")(dec_out)\n",
        "model = models.Model([enc_in, dec_in], outputs)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
        "model.fit([x_enc, x_dec], y_train, epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuv5H3yAnIyi",
        "outputId": "8ca339fb-e3bd-41a2-f025-56f60eef552e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7edb1a3194f0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ۶. تابع تست (Inference) برای ترجمه داده جدید\n",
        "def translate(sentence):\n",
        "    # تبدیل ورودی انگلیسی به ID\n",
        "    enc_input = [en_vocab.get(w, 0) for w in sentence.split()]\n",
        "    enc_input = np.array([enc_input + [0] * (maxlen - len(enc_input))])\n",
        "\n",
        "    # شروع با توکن <START>\n",
        "    dec_input_ids = [fa_vocab[\"<START>\"]]\n",
        "\n",
        "    for _ in range(maxlen - 1):\n",
        "        pad_dec = dec_input_ids + [0] * (maxlen - len(dec_input_ids))\n",
        "        preds = model.predict([enc_input, np.array([pad_dec])], verbose=0)\n",
        "\n",
        "        # انتخاب کلمه با بیشترین احتمال در جایگاه فعلی\n",
        "        next_id = np.argmax(preds[0, len(dec_input_ids)-1, :])\n",
        "        if next_id == fa_vocab[\"<END>\"] or next_id == 0:\n",
        "            break\n",
        "        dec_input_ids.append(next_id)\n",
        "\n",
        "    return \" \".join([inv_fa_vocab[i] for i in dec_input_ids if i in inv_fa_vocab])\n",
        "\n",
        "# تست نهایی\n",
        "print(\"--- تست مدل ---\")\n",
        "print(f\"Input: hello -> Output: {translate('hello')}\")\n",
        "print(f\"Input: bye   -> Output: {translate('bye')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRAtGltrnsvy",
        "outputId": "03f2ec7b-75fa-4a64-de1e-391b2db128c5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- تست مدل ---\n",
            "Input: hello -> Output: <START> سلام\n",
            "Input: bye   -> Output: <START> خداحافظ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QFnH_Axqpapb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}